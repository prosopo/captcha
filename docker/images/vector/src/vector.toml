# enable vector's api
[api]
enabled = true
# only allow localhost to hit the api
address = "127.0.0.1:8686"

# take logs from docker containers with the correct label set
[sources.provider]
type = "docker_logs"
include_labels = ["vector.provider=true"]

# format the logs for a provider
[transforms.provider_format]
type = "remap"
inputs = ["provider"]
source = '''
output={}
parsed=parse_json(.message) ?? null
if parsed != null {
    output = parsed
} else {
    output.message = .message
}
output.host=get_env_var!("OO_HOST")
output.container_name=.container_name
output.image=.image
output.stream=.stream
output.source_type=.source_type
.=output
'''

# print to console the provider logs
#[sinks.console]
#type = "console"
#inputs = ["provider_format"]
#encoding.codec = "json"

# send provider logs to tiger-stairs
[sinks.oo_provider]
type = "http"
inputs = ["provider_format"]
uri = "https://oo.prosopo.io/api/dev_organization_29569_u24VnjrjN7XrP35/${NODE_ENV:?err}_provider_node/_json"
method = "post"
auth.strategy = "basic"
auth.user = "${OO_USERNAME:?err}"
auth.password = "${OO_PASSWORD:?err}"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 15
request.rate_limit_duration_secs = 1
request.rate_limit_num = 10
buffer.type = "disk"
buffer.max_size = 268435488
compression = "gzip"

[sinks.oo2_provider]
type = "http"
inputs = ["provider_format"]
uri = "https://oo2.prosopo.io/api/default/${NODE_ENV:?err}_provider_node/_json"
method = "post"
auth.strategy = "basic"
auth.user = "${OO_USERNAME:?err}"
auth.password = "${OO_PASSWORD:?err}"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 15
request.rate_limit_duration_secs = 1
request.rate_limit_num = 10
buffer.type = "disk"
buffer.max_size = 268435488
compression = "gzip"

# listen to docker events for containers starting+ending
[sources.docker]
type = "exec"
# only containers with the correct label are listened to
# https://docs.docker.com/reference/cli/docker/system/events/#containers
# start – Indicates that the container has been started.
# stop – Indicates that the container has been stopped.
# restart – Indicates that the container has been restarted.
# die – Indicates that the container has stopped running (either due to a crash or intentional termination).
# pause – Indicates that the container is paused, meaning it is not actively running but hasn't been stopped.
# unpause – Indicates that the container has resumed running after being paused.
# kill – Indicates that the container has been forcefully terminated.
# oom – Indicates that the container was terminated due to running out of memory (Out-Of-Memory).
command = [ "docker", "events", "--format", "json", "--filter", "label=vector.docker=true", "--filter", "event=start", "--filter", "event=stop", "--filter", "event=restart", "--filter", "event=die", "--filter", "event=pause", "--filter", "event=unpause", "--filter", "event=kill", "--filter", "event=oom" ]
mode = "streaming"
decoding.codec = "json"

# delete useless info and add the host to identify what machine the logs are coming from
[transforms.docker_format]
type = "remap"
inputs = ["docker"]
source = '''
output={}
parsed=parse_json(.message) ?? null
if parsed != null {
    output = parsed
} else {
    output.message = .message
}
output.host=get_env_var!("OO_HOST")
output.container_name=.container_name
output.image=.image
output.stream=.stream
output.source_type=.source_type
output.name=.Actor.Attributes.name
.=output
'''

# print docker events to console
#[sinks.console]
#type = "console"
#inputs = ["docker_format"]
#encoding.codec = "json"

# send to openobserve
[sinks.oo_docker]
type = "http"
inputs = ["docker_format"]
uri = "https://oo.prosopo.io/api/dev_organization_29569_u24VnjrjN7XrP35/${NODE_ENV:?err}_provider_docker/_json"
method = "post"
auth.strategy = "basic"
auth.user = "${OO_USERNAME:?err}"
auth.password = "${OO_PASSWORD:?err}"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 15
request.rate_limit_duration_secs = 1
request.rate_limit_num = 10
buffer.type = "disk"
buffer.max_size = 268435488

[sinks.oo2_docker]
type = "http"
inputs = ["docker_format"]
uri = "https://oo2.prosopo.io/api/default/${NODE_ENV:?err}_provider_docker/_json"
method = "post"
auth.strategy = "basic"
auth.user = "${OO_USERNAME:?err}"
auth.password = "${OO_PASSWORD:?err}"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 15
request.rate_limit_duration_secs = 1
request.rate_limit_num = 10
buffer.type = "disk"
buffer.max_size = 268435488

[sources.caddy]
type = "docker_logs"
include_labels = ["vector.caddy=true"]

[transforms.caddy_format]
type = "remap"
inputs = ["caddy"]
source = '''
output={}
parsed=parse_json(.message) ?? null
if parsed != null {
    output = parsed
} else {
    output.message = .message
}
output.host=get_env_var!("OO_HOST")
output.container_name=.container_name
output.image=.image
output.stream=.stream
output.source_type=.source_type
output.request_id = get(.resp_headers, ["X-Request-Id"])[0] ?? null
.=output
'''

# send to openobserve
[sinks.oo_caddy]
type = "http"
inputs = ["caddy_format"]
uri = "https://oo.prosopo.io/api/dev_organization_29569_u24VnjrjN7XrP35/${NODE_ENV:?err}_provider_caddy/_json"
method = "post"
auth.strategy = "basic"
auth.user = "${OO_USERNAME:?err}"
auth.password = "${OO_PASSWORD:?err}"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 15
request.rate_limit_duration_secs = 1
request.rate_limit_num = 10
buffer.type = "disk"
buffer.max_size = 268435488

[sinks.oo2_caddy]
type = "http"
inputs = ["caddy_format"]
uri = "https://oo2.prosopo.io/api/dev_organization_29569_u24VnjrjN7XrP35/${NODE_ENV:?err}_provider_caddy/_json"
method = "post"
auth.strategy = "basic"
auth.user = "${OO_USERNAME:?err}"
auth.password = "${OO_PASSWORD:?err}"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 15
request.rate_limit_duration_secs = 1
request.rate_limit_num = 10
buffer.type = "disk"
buffer.max_size = 268435488
