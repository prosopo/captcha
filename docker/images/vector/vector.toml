# enable vector's api
[api]
enabled = true
# only allow localhost to hit the api
address = "127.0.0.1:8686"

# take logs from docker containers with the correct label set
[sources.provider]
type = "docker_logs"
include_labels = ["vector.provider=true"]

# format the logs for a provider
[transforms.provider_format]
type = "remap"
inputs = ["provider"]
source = '''
.=parse_json!(.message)
del(.message)
del(.timestamp)
del(._timestamp)
.host="$OO_HOST"
del(.date)
'''

# print to console the provider logs
#[sinks.console]
#type = "console"
#inputs = ["provider_format"]
#encoding.codec = "json"

# send provider logs to openobserve
[sinks.openobserve_provider]
type = "http"
inputs = ["provider_format"]
uri = "https://api.openobserve.ai/api/$OO_ORG/${NODE_ENV}_provider_node/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO_USERNAME"
auth.password = "$OO_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch

# send provider logs to tiger-stairs
[sinks.prosopo_provider]
type = "http"
inputs = ["provider_format"]
uri = "https://oo.prosopo.io/api/$OO_ORG/${NODE_ENV}_provider_node/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO_USERNAME"
auth.password = "$OO_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch

[sinks.prosopo_provider2]
type = "http"
inputs = ["caddy_format"]
uri = "https://oo2.prosopo.io/api/$OO_ORG/${NODE_ENV}_provider_node/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO2_USERNAME"
auth.password = "$OO2_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch

# listen to docker events for containers starting+ending
[sources.docker]
type = "exec"
# only containers with the correct label are listened to
# https://docs.docker.com/reference/cli/docker/system/events/#containers
# start – Indicates that the container has been started.
# stop – Indicates that the container has been stopped.
# restart – Indicates that the container has been restarted.
# die – Indicates that the container has stopped running (either due to a crash or intentional termination).
# pause – Indicates that the container is paused, meaning it is not actively running but hasn't been stopped.
# unpause – Indicates that the container has resumed running after being paused.
# kill – Indicates that the container has been forcefully terminated.
# oom – Indicates that the container was terminated due to running out of memory (Out-Of-Memory).
command = [ "docker", "events", "--format", "json", "--filter", "label=vector.docker=true", "--filter", "event=start", "--filter", "event=stop", "--filter", "event=restart", "--filter", "event=die", "--filter", "event=pause", "--filter", "event=unpause", "--filter", "event=kill", "--filter", "event=oom" ]
mode = "streaming"
decoding.codec = "json"

# delete useless info and add the host to identify what machine the logs are coming from
[transforms.docker_format]
type = "remap"
inputs = ["docker"]
source = '''
.host="$OO_HOST"
del(.id)
del(.from)
del(.Type)
.name=.Actor.Attributes.name
del(.Actor)
del(.scope)
del(.time)
del(.timeNano)
del(.source_type)
del(.timestamp)
del(._timestamp)
del(.pid)
del(.stream)
del(.command)
'''

# print docker events to console
[sinks.console]
type = "console"
inputs = ["docker_format"]
encoding.codec = "json"

# send to openobserve
[sinks.openobserve_docker]
type = "http"
inputs = ["docker_format"]
uri = "https://api.openobserve.ai/api/$OO_ORG/${NODE_ENV}_provider_docker/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO_USERNAME"
auth.password = "$OO_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch

# send to openobserve
[sinks.prosopo_docker]
type = "http"
inputs = ["docker_format"]
uri = "https://oo.prosopo.io/api/$OO_ORG/${NODE_ENV}_provider_docker/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO_USERNAME"
auth.password = "$OO_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch

[sinks.prosopo_docker2]
type = "http"
inputs = ["caddy_format"]
uri = "https://oo2.prosopo.io/api/$OO_ORG/${NODE_ENV}_provider_docker/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO2_USERNAME"
auth.password = "$OO2_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch

[sources.caddy]
type = "docker_logs"
include_labels = ["vector.caddy=true"]

[transforms.caddy_format]
type = "remap"
inputs = ["caddy"]
source = '''
.=parse_json!(string!(.message))
.host="$OO_HOST"
.request_id = get!(.resp_headers, ["X-Request-Id"])[0]
del(.timestamp)
del(._timestamp)
del(.ts)
del(.user_id)
del(.size)
del(.message)
del(.resp_headers)
del(.bytes_read)
del(.logger)
'''

# send to openobserve
[sinks.openobserve_caddy]
type = "http"
inputs = ["caddy_format"]
uri = "https://api.openobserve.ai/api/$OO_ORG/${NODE_ENV}_provider_caddy/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO_USERNAME"
auth.password = "$OO_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch

# send to openobserve
[sinks.prosopo_caddy]
type = "http"
inputs = ["caddy_format"]
uri = "https://oo.prosopo.io/api/$OO_ORG/${NODE_ENV}_provider_caddy/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO_USERNAME"
auth.password = "$OO_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch

[sinks.prosopo_caddy2]
type = "http"
inputs = ["caddy_format"]
uri = "https://oo2.prosopo.io/api/$OO_ORG/${NODE_ENV}_provider_caddy/_json"
method = "post"
auth.strategy = "basic"
auth.user = "$OO2_USERNAME"
auth.password = "$OO2_PASSWORD"
compression = "gzip"
encoding.codec = "json"
encoding.timestamp_format = "rfc3339"
healthcheck.enabled = true
batch.timeout_secs = 10 # time to wait before sending a batch
batch.max_bytes = 10485760 # 10mb, max number of bytes per batch
batch.max_events = 100000 # max number of events per batch
